{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU memory usage for deep learning image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目的\n",
    "DLによる画像処理について、モデルの学習と実行に必要なGPUメモリー容量の理論値と実測値の差を検証する。\n",
    "\n",
    "### 方法\n",
    "以下の４つの項目について、メモリの使用量の理論値と実測値を比較する。\n",
    "   \n",
    "1. 変数\n",
    "2. Convolutional Neural Network\n",
    "3. VGG16\n",
    "4. ResNet50\n",
    "5. Vision Transformer\n",
    "6. UNETR\n",
    "\n",
    "メモリの使用量の実測値は、pytorchもしくはtensorflowの関数と、nvml（nvidia  management library）の関数で測定する。\n",
    "pytorchやtensorflowの関数ではプログラム中で確保された容量が測定される。一方、nvmlではプログラム実行に必要なpythonやcudaなどのオーバーヘッドを含んだ容量が測定される。\n",
    "変数とUNETRについては２つの実装方法（pytorch, tensorflow）で実測値を測定する。どちらの実装方法でも実測値に大きな差はないことが期待される。\n",
    "\n",
    "### 結果\n",
    "|  | 理論値[MiB] | 実測値[MiB] | 誤差[%] |\n",
    "|---|---|---|---|\n",
    "| 変数 | 1024 | 1024 | 0 |\n",
    "| CNN | 636 | 531 | 19.8 |\n",
    "| VGG16 | 15929 | 17232 | 7.6 |\n",
    "| ResNet50 | 11378 | 11738 | 3.1 |\n",
    "| ViT | 13290 | 17217 | 22.8 |\n",
    "| UNETR |  |  |  |\n",
    "\n",
    "#### 検証環境\n",
    "- python 3.10\n",
    "- tensorflow 2.13.0\n",
    "- torch 2.0.1\n",
    "- NVIDIA driver 530.30.02\n",
    "- CUDA toolkit 11.8\n",
    "- cuDNN 8.9\n",
    "\n",
    "#### 参考文献\n",
    "1. [Estimating GPU Memory Consumption of Deep Learning Models](https://2020.esec-fse.org/details/esecfse-2020-industry-papers/5/Estimating-GPU-Memory-Consumption-of-Deep-Learning-Models), [video](https://dl.acm.org/doi/10.1145/3368089.3417050)\n",
    "2. [A comprehensive guide to memory usage in PyTorch](https://medium.com/deep-learning-for-protein-design/a-comprehensive-guide-to-memory-usage-in-pytorch-b9b7c78031d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 変数\n",
    "float32型（4byte）で0.25GiB次元の変数を考える。この変数は理論値で1GiBのサイズである。\n",
    "\n",
    "変数を定義または削除したときのメモリの使用量を確認して、実測値を求める。\n",
    "まず、Pytorchでの実測値を求める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_cpu dtype: torch.float32, dim: 256.0MiB\n",
      "Initial: allocated = 0.0 MiB, reserved = 0.0MiB, max allocated = 0.0 MiB, used = 673.6 MiB\n",
      "Define: allocated = 1024.0 MiB, reserved = 1024.0MiB, max allocated = 1024.0 MiB, used = 2497.6 MiB\n",
      "Delete: allocated = 0.0 MiB, reserved = 1024.0MiB, max allocated = 1024.0 MiB, used = 2497.6 MiB\n",
      "Release: allocated = 0.0 MiB, reserved = 0.0MiB, max allocated = 1024.0 MiB, used = 1473.6 MiB\n"
     ]
    }
   ],
   "source": [
    "import pynvml\n",
    "import torch\n",
    "\n",
    "\n",
    "def print_memory_torch(prefix: str):\n",
    "    \"\"\"Print memory usage.\n",
    "    \"\"\"    \n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    info = pynvml.nvmlDeviceGetMemoryInfo(handle)    \n",
    "    memory_al = torch.cuda.memory_allocated()\n",
    "    memory_res = torch.cuda.memory_reserved()\n",
    "    memory_maxal = torch.cuda.max_memory_allocated()\n",
    "\n",
    "    print(f\"{prefix}: allocated = {memory_al/1024**2:.1f} MiB, \"\n",
    "        f\"reserved = {memory_res/1024**2:.1f}MiB, \"\n",
    "        f\"max allocated = {memory_maxal/1024**2:.1f} MiB, \"\n",
    "        f\"used = {info.used/1024**2:.1f} MiB\")\n",
    "\n",
    "\n",
    "# Define a variable with 1GiB.\n",
    "dim = 1024**3//4\n",
    "var_cpu = torch.zeros(dim, dtype=torch.float32)\n",
    "print(f\"var_cpu dtype: {var_cpu.dtype}, dim: {dim/1024**2}MiB\")\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "print_memory_torch(\"Initial\")\n",
    "\n",
    "# Copy the variable to gpu.\n",
    "var_gpu = var_cpu.to(\"cuda\")\n",
    "print_memory_torch(\"Define\")\n",
    "\n",
    "# Delete the variable from gpu.\n",
    "del var_gpu\n",
    "print_memory_torch(\"Delete\")\n",
    "\n",
    "# Release cached memory.\n",
    "torch.cuda.empty_cache()\n",
    "print_memory_torch(\"Release\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数を定義した後に1024MiB=1GiBのVRAMが確保されたので、実測値は理論値と一致した。\n",
    "delで変数を削除したあともメモリはreservedとして確保されており、torch.cuda.empty_cache()によって完全にメモリが解放された。\n",
    "\n",
    "nvmlのusedの結果から、実際には変数のサイズ以上のメモリが確保され、変数を削除した後にもオーバーヘッド分が残っていた。\n",
    "\n",
    "次にTensorFlowでの実測値を求める。\n",
    "Tensorflowはデフォルトでプログラム開始時にメモリを最大限確保する。必要なメモリだけを確保するために、memory growthを有効にする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-09 20:23:10.003822: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-09 20:23:10.024979: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-09 20:23:10.430311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-09 20:23:10.910824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-09 20:23:10.911431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-09 20:23:10.911487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_cpu dtype: float32, dim: 256.0MiB\n",
      "Initail: current = 0.0 MiB, peak = 0.0MiB, used = 1650.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-09 20:23:10.945510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-09 20:23:10.945638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-09 20:23:10.945710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-09 20:23:11.214962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-09 20:23:11.215046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-09 20:23:11.215093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-09 20:23:11.215137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21377 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define: current = 1024.0 MiB, peak = 1024.0MiB, used = 3717.6 MiB\n",
      "Delete: current = 0.0 MiB, peak = 1024.0MiB, used = 3717.6 MiB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_memory_tf(prefix: str):\n",
    "    \"\"\"Print memory usage.\n",
    "    \"\"\"\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    info = pynvml.nvmlDeviceGetMemoryInfo(handle)  \n",
    "    memory_info = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "\n",
    "    print(f\"{prefix}: current = {memory_info['current']/1024**2:.1f} MiB, \"\n",
    "        f\"peak = {memory_info['peak']/1024**2:.1f}MiB, \"\n",
    "        f\"used = {info.used/1024**2:.1f} MiB\")\n",
    "\n",
    "\n",
    "# Enabled memory growth.\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(devices[0], True)\n",
    "\n",
    "# Define a variable with 1GiB.\n",
    "dim = 1024**3//4\n",
    "var_cpu = np.zeros(dim, dtype=np.float32)\n",
    "print(f\"var_cpu dtype: {var_cpu.dtype}, dim: {dim/1024**2}MiB\")\n",
    "\n",
    "tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "print_memory_tf(\"Initail\")\n",
    "\n",
    "# Copy the variable to gpu.\n",
    "with tf.device(\"GPU\"):\n",
    "    var_gpu = tf.constant(var_cpu)\n",
    "print_memory_tf(\"Define\")\n",
    "\n",
    "# Delete the variable from gpu.\n",
    "del var_gpu\n",
    "print_memory_tf(\"Delete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数を定義した後に1GiBのVRAMが確保されたので、実測値は理論値と一致した。\n",
    "オーバーヘッドも含めると、実際には変数のサイズ以上のメモリが確保され、変数を削除したあとも解放されなかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "画像分類をする単純なCNNについて、メモリー使用量の理論値と実測値を比較する。\n",
    "\n",
    "データセットは疑似乱数で作成する。\n",
    "入力画像は3x224x224次元として、1280枚を用意する。\n",
    "分類クラスは10個として、one-hot encodingで表現する。\n",
    "バッチサイズは128とする。\n",
    "\n",
    "CNNは、畳み込み層、平均プーリング層、全結合層を1つずつ持つ構造とする。\n",
    "畳み込み層は、カーネル3x3、チャンネル数8、ストライド1、パディングなし、バイアスありとする。\n",
    "平均プーリング層は、カーネル2x2、ストライド2、パディングなしとする。\n",
    "全結合層は10次元の出力である。\n",
    "学習の最適化にはSGDを用いる。\n",
    "数値の精度はPytorchのデフォルトであるfloat32とする。\n",
    "\n",
    "このCNNに必要なメモリの理論値を求める。\n",
    "参考文献1,2によれば、学習と推論に必要なメモリは各々以下のようになる。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{usage for training}   &= \\text{data} + \\text{weight} + \\text{forward output} + \\text{weight gradient} + \\text{output gradient} \\\\\n",
    "                            &= D + W + O * b + W * (d + m) + (O + D) \\\\\n",
    "\\text{usage for inference}  &= \\text{data} + \\text{weight} + \\text{forward output} \\\\\n",
    "                            &= D + W + O \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "ここで、  \n",
    "$D$: ミニバッチのデータセットのメモリ使用量  \n",
    "$W$: 学習パラメーターのメモリ使用量  \n",
    "$O$: 中間層の出力のメモリ使用量  \n",
    "$b$: 推論時に中間層の出力のみ半精度にするMixed Precisionを利用する場合は0.5、そうでない場合は1  \n",
    "$d$: 複数のGPUで実行するDistributed Data Parallelを利用する場合は2、そうでない場合は1  \n",
    "$m$: 最適化で使うモーメントの数（SGD: 0, Adagrad, RMSprop: 1, Adam: 2）\n",
    "\n",
    "実際にはこれに加えて、GPUでの計算に必要なメモリー（CUDA context、cuDNN Workspace）とメモリ管理の最適化のための余剰メモリー（Internal Tensor Fragmentation）が使用される。文献1によれば、この追加分はライブラリーのバージョンやモデルによって変わるが、0.5GB程度である。\n",
    "\n",
    "今回のCNNの場合は、メモリー使用量の理論値は以下のように求まる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.dim_input = [3,224,224]\n",
    "        self.dim_output = 10\n",
    "        self.datasize = 1280\n",
    "        self.batchsize = 128\n",
    "        self.num_epochs = 3\n",
    "        self.lr = 1e-2\n",
    "        self.device = 'cuda'\n",
    "        self.optim = optim.SGD\n",
    "        self.moment = 0         # SGD: 0, Adagrad, RMSprop: 1, Adam: 2\n",
    "        self.ddp = 1            # Distributed data parallel: 2, Not: 1\n",
    "        self.mixed_pre = 1      # Mixed precision: 0.5, Not: 1\n",
    "\n",
    "\n",
    "conf = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(MiB): 73.5\n",
      "Weight(MiB): 3.8\n",
      "Forward output(MiB): 240.6\n",
      "Weight gradient(MiB): 3.8\n",
      "Output gradient(MiB): 314.1\n",
      "Total for training(MiB): 635.8\n",
      "Total for inference(MiB): 317.9\n"
     ]
    }
   ],
   "source": [
    "def print_memory_estimate1(\n",
    "    dim_input: list, \n",
    "    dim_output: list, \n",
    "    num_param: int, \n",
    "    num_hidden_output: int, \n",
    "    moment: int, \n",
    "    ddp: int = 1, \n",
    "    mixed_pre: float = 1):\n",
    "    '''Print theoretical memory usage.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dim_input: Shape of input data including batch size. e.g. [batch size, channel, width, height]\n",
    "    dim_output: Shape of output data.\n",
    "    num_param: Number of trainable parameters.\n",
    "    num_hidden_output: Total number of hidden layer's output. Don't include in-place hidden layer that require no additional memory (Activations, Normalizations).\n",
    "    moment: Moment use for optimization. SGD: 0, Adagrad, RMSprop: 1, Adam: 2\n",
    "    ddp: Multiple GPU use. Distributed data parallel: 2, Not: 1\n",
    "    mixed_pre: Forward outputs memory saving by Mixed precision: 0.5, Not: 1\n",
    "    '''\n",
    "    mem_data = (np.prod(dim_input) + np.prod(dim_output)) * 4\n",
    "    mem_weight = num_param * 4\n",
    "    mem_weight_grad = mem_weight * (ddp + moment)\n",
    "    mem_forward_output = num_hidden_output * 4 * mixed_pre\n",
    "    mem_output_gradient = mem_forward_output + mem_data\n",
    "    mem_training = mem_data + mem_weight + mem_forward_output + mem_weight_grad + mem_output_gradient\n",
    "    mem_inference = mem_data + mem_weight + mem_forward_output\n",
    "\n",
    "    print(f\"Data(MiB): {mem_data/1024**2:.1f}\")\n",
    "    print(f\"Weight(MiB): {mem_weight/1024**2:.1f}\")\n",
    "    print(f\"Forward output(MiB): {mem_forward_output/1024**2:.1f}\")\n",
    "    print(f\"Weight gradient(MiB): {mem_weight_grad/1024**2:.1f}\")\n",
    "    print(f\"Output gradient(MiB): {mem_output_gradient/1024**2:.1f}\")\n",
    "    print(f\"Total for training(MiB): {mem_training/1024**2:.1f}\")\n",
    "    print(f\"Total for inference(MiB): {mem_inference/1024**2:.1f}\")\n",
    "\n",
    "\n",
    "num_param = 3*3*3*8+8 + 8*((conf.dim_input[1]-2)//2)*((conf.dim_input[2]-2)//2)*10 + 10\n",
    "num_output_shape = np.prod([conf.batchsize, 8, (conf.dim_input[1]-2), (conf.dim_input[2]-2)]) \\\n",
    "                 + np.prod([conf.batchsize, 8, ((conf.dim_input[1]-2)//2), ((conf.dim_input[2]-2)//2)])\n",
    "\n",
    "print_memory_estimate1([conf.batchsize] + conf.dim_input, conf.dim_output,\n",
    "                        num_param, num_output_shape, conf.moment, conf.ddp, conf.mixed_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よって、理論値は636MiBである。\n",
    "\n",
    "次にpytorchでCNNを実行したときのメモリ使用量の実測値を調べる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: allocated = 0.0 MiB, reserved = 0.0MiB, max allocated = 0.0 MiB, used = 3717.6 MiB\n",
      "Model: allocated = 3.8 MiB, reserved = 22.0MiB, max allocated = 3.8 MiB, used = 3739.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|██████████| 10/10 [00:00<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 97.8 MiB, reserved = 604.0MiB, max allocated = 530.9 MiB, used = 5001.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 10/10 [00:00<00:00, 108.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 97.8 MiB, reserved = 604.0MiB, max allocated = 530.9 MiB, used = 5001.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|██████████| 10/10 [00:00<00:00, 108.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 97.8 MiB, reserved = 604.0MiB, max allocated = 530.9 MiB, used = 5001.4 MiB\n",
      "Final: allocated = 97.8 MiB, reserved = 604.0MiB, max allocated = 530.9 MiB, used = 5001.4 MiB\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CNN(nn.Module):    \n",
    "    def __init__(self, dim_c: int, dim_h: int, dim_w: int):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=dim_c, out_channels=8, kernel_size=3)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(8*((dim_h-2)//2)*((dim_w-2)//2), 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def train(\n",
    "    model:nn.Module, \n",
    "    dim_input: list, \n",
    "    batchsize: int, \n",
    "    epoch: int, \n",
    "    optimizer: optim.Optimizer = optim.SGD, \n",
    "    device: str = \"cuda\"):\n",
    "    \"\"\"Train model using random dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: \n",
    "    dim_input: Shape of input data including data size. e.g. [data size, channel, width, height]\n",
    "    batchsize:\n",
    "    epoch:\n",
    "    optimizer:\n",
    "    device: \n",
    "    \"\"\"\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    print_memory_torch(\"Initial\")\n",
    "\n",
    "    model.to(device)\n",
    "    print_memory_torch(\"Model\")\n",
    "\n",
    "    data = [[torch.randn([batchsize, dim_input[1], dim_input[2], dim_input[3]]), \n",
    "             torch.randn(batchsize, 10)] \n",
    "             for _ in range(dim_input[0]//batchsize)]\n",
    "\n",
    "    criterion = F.cross_entropy\n",
    "    opt = optimizer(model.parameters(), lr=0.01)\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        with tqdm(data) as pbar:\n",
    "            pbar.set_description(f'[Epoch {ep + 1}]')\n",
    "            for x, y in pbar:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                opt.zero_grad()\n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            \n",
    "        print_memory_torch(\"Train\")\n",
    "    print_memory_torch(\"Final\")\n",
    "\n",
    "\n",
    "model_cnn = CNN(conf.dim_input[0], conf.dim_input[1], conf.dim_input[2])\n",
    "train(model_cnn, [conf.datasize] + conf.dim_input, conf.batchsize, conf.num_epochs,\n",
    "      conf.optim, conf.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを用意したときの実測値は3.8MiBであり、理論値と一致した。\n",
    "学習終了時の実測ピーク値は531MiBであり、理論値と19.8%の誤差があった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "pytorchでは、torchinfoを使うとネットワーク構造やパラメータ数、メモリー使用量の情報を取得・表示できる。この機能は理論値を計算する際に便利であるが、メモリー使用量の計算は上記理論式と異なる。\n",
    "\n",
    "具体的には、メモリー使用量＝入力データ＋順伝搬/逆伝搬サイズ＋Weightとしている。順伝搬/逆伝搬サイズForward/backward pass sizeは、学習する層の出力サイズの合計を求め、gradientを考慮してその２倍をメモリー使用量としている。よって、上記理論式とは全く異なる。\n",
    "また、メモリー使用量の表示がMiBではなくMBである。（1MB = 1000^2byte, 1MiB = 1,024^2byte）\n",
    "\n",
    "今回のCNNでのtorchinfoの表示は以下のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #                   Kernel Shape\n",
      "===================================================================================================================\n",
      "CNN                                      [128, 10]                 --                        --\n",
      "├─Conv2d: 1-1                            [128, 8, 222, 222]        224                       [3, 3]\n",
      "├─AvgPool2d: 1-2                         [128, 8, 111, 111]        --                        2\n",
      "├─Linear: 1-3                            [128, 10]                 985,690                   --\n",
      "===================================================================================================================\n",
      "Total params: 985,914\n",
      "Trainable params: 985,914\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.54\n",
      "===================================================================================================================\n",
      "Input size (MB): 77.07\n",
      "Forward/backward pass size (MB): 403.74\n",
      "Params size (MB): 3.94\n",
      "Estimated Total Size (MB): 484.76\n",
      "===================================================================================================================\n",
      "Total prams:  985914\n",
      "Input size(byte):  77070336\n",
      "Forward/backward(byte):  403744768\n",
      "Params size(byte):  3943656\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "result = summary(model_cnn, [conf.batchsize] + conf.dim_input,\n",
    "        col_names=(\"output_size\", \"num_params\", \"kernel_size\"))\n",
    "print(result)\n",
    "\n",
    "# Confirm result\n",
    "num_input = conf.batchsize * conf.dim_input[0] * conf.dim_input[1] * conf.dim_input[2]\n",
    "num_param = conf.dim_input[0]*3*3*8 + 8 + 8*((conf.dim_input[1]-2)//2)*((conf.dim_input[2]-2)//2)*conf.dim_output + conf.dim_output\n",
    "num_hidden_output = np.prod([conf.batchsize, 8, conf.dim_input[1]-2, conf.dim_input[2]-2]) + np.prod([conf.batchsize, conf.dim_output])\n",
    "\n",
    "print(\"Total prams: \", num_param)\n",
    "print(\"Input size(byte): \", num_input * 4)\n",
    "print(\"Forward/backward(byte): \", 2 * num_hidden_output * 4) # https://github.com/sksq96/pytorch-summary/issues/51\n",
    "print(\"Params size(byte): \", num_param * 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchinfoを利用して、定義したmodelからパラメータ数や中間層出力の数を自動的に計算して、理論値を計算できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(MiB): 73.5\n",
      "Weight(MiB): 3.8\n",
      "Forward output(MiB): 240.6\n",
      "Weight gradient(MiB): 3.8\n",
      "Output gradient(MiB): 314.1\n",
      "Total for training(MiB): 635.8\n",
      "Total for inference(MiB): 317.9\n"
     ]
    }
   ],
   "source": [
    "def is_memoryless(class_name: str) -> bool:\n",
    "    ''' Return True if the class is memoryless type.\n",
    "    Activations, normalizations and dropouts perform in-place updates by default\n",
    "    and does not require additional memory.\n",
    "    '''\n",
    "    return any((class_name == \"ReLU\",\n",
    "           class_name == \"LeakyReLU\",\n",
    "           class_name == \"Sigmoid\",\n",
    "           class_name == \"Tanh\",\n",
    "           class_name == \"ELU\",\n",
    "           class_name == \"GLU\",\n",
    "           class_name == \"PReLU\",\n",
    "           class_name == \"GELU\",\n",
    "           class_name == \"Mish\",\n",
    "           class_name == \"Softmin\",\n",
    "           class_name == \"Softmax\",\n",
    "           class_name == \"Softmax2d\",\n",
    "           class_name == \"BatchNorm1d\",\n",
    "           class_name == \"BatchNorm2d\",\n",
    "           class_name == \"BatchNorm3d\",\n",
    "           class_name == \"Dropout\",\n",
    "           class_name == \"Dropout1d\",\n",
    "           class_name == \"Dropout2d\",\n",
    "           class_name == \"Dropout3d\",\n",
    "           class_name == \"AlphaDropout\"))\n",
    "\n",
    "def print_memory_estimate2(\n",
    "    model: nn.Module, \n",
    "    dim_input: list, \n",
    "    moment: int, \n",
    "    ddp: int=1, \n",
    "    mixed_pre: float = 1):\n",
    "    '''Print theoretical memory usage.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: \n",
    "    dim_input: Shape of input data including batch size. e.g. [batch size, channel, width, height]\n",
    "    moment: Moment use for optimization. SGD: 0, Adagrad, RMSprop: 1, Adam: 2\n",
    "    ddp: Multiple GPU use. Distributed data parallel: 2, Not: 1\n",
    "    mixed_pre: Forward outputs memory saving by Mixed precision: 0.5, Not: 1\n",
    "    '''\n",
    "    info = summary(model, dim_input, verbose=0)\n",
    "    dim_output = info.summary_list[-1].output_size[1:]\n",
    "\n",
    "    num_param = 0\n",
    "    num_output_shape = 0\n",
    "    last_layer = len(info.summary_list) -1\n",
    "    # print(\"#, Class, Leaf, Memoryless, Output\")\n",
    "    for i, layer in enumerate(info.summary_list):\n",
    "        # print(f\"{i}, {layer.class_name}, {layer.is_leaf_layer}, {is_memoryless(layer.class_name)}, {layer.output_size}\")\n",
    "        if layer.is_leaf_layer:\n",
    "            num_param += layer.trainable_params\n",
    "            if i != last_layer and not is_memoryless(layer.class_name):\n",
    "                num_output_shape += np.prod(layer.output_size)\n",
    "    \n",
    "    mem_data = (np.prod(dim_input) + np.prod(dim_output)) * 4\n",
    "    mem_weight = num_param * 4\n",
    "    mem_weight_grad = mem_weight * (ddp + moment)\n",
    "    mem_forward_output = num_output_shape * 4 * mixed_pre\n",
    "    mem_output_gradient = mem_forward_output + mem_data\n",
    "    mem_training = mem_data + mem_weight + mem_forward_output + mem_weight_grad + mem_output_gradient\n",
    "    mem_inference = mem_data + mem_weight + mem_forward_output\n",
    "\n",
    "    print(f\"Data(MiB): {mem_data/1024**2:.1f}\")\n",
    "    print(f\"Weight(MiB): {mem_weight/1024**2:.1f}\")\n",
    "    print(f\"Forward output(MiB): {mem_forward_output/1024**2:.1f}\")\n",
    "    print(f\"Weight gradient(MiB): {mem_weight_grad/1024**2:.1f}\")\n",
    "    print(f\"Output gradient(MiB): {mem_output_gradient/1024**2:.1f}\")\n",
    "    print(f\"Total for training(MiB): {mem_training/1024**2:.1f}\")\n",
    "    print(f\"Total for inference(MiB): {mem_inference/1024**2:.1f}\")\n",
    "\n",
    "\n",
    "print_memory_estimate2(model_cnn, [conf.batchsize] + conf.dim_input, \n",
    "                       conf.moment, conf.ddp, conf.mixed_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Estimated ===\n",
      "Data(MiB): 73.5\n",
      "Weight(MiB): 512.4\n",
      "Forward output(MiB): 7378.5\n",
      "Weight gradient(MiB): 512.4\n",
      "Output gradient(MiB): 7452.0\n",
      "Total for training(MiB): 15928.7\n",
      "Total for inference(MiB): 7964.4\n",
      "=== Real ===\n",
      "Initial: allocated = 537.1 MiB, reserved = 678.0MiB, max allocated = 537.1 MiB, used = 5077.4 MiB\n",
      "Model: allocated = 537.1 MiB, reserved = 678.0MiB, max allocated = 537.1 MiB, used = 5077.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|██████████| 10/10 [00:03<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 1125.1 MiB, reserved = 18752.0MiB, max allocated = 17231.9 MiB, used = 23131.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 10/10 [00:04<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 1125.1 MiB, reserved = 18752.0MiB, max allocated = 17231.9 MiB, used = 23131.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|██████████| 10/10 [00:04<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 1125.1 MiB, reserved = 18752.0MiB, max allocated = 17231.9 MiB, used = 23131.1 MiB\n",
      "Final: allocated = 1125.1 MiB, reserved = 18752.0MiB, max allocated = 17231.9 MiB, used = 23131.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model_vgg16 = models.vgg16_bn(weights=None)\n",
    "model_vgg16.classifier[6] = nn.Linear(model_vgg16.classifier[6].in_features, 10) # Change the num of final output features to 10\n",
    "# print(model_vgg16)\n",
    "\n",
    "# result = summary(model_vgg16, [conf.batchsize] + conf.dim_input,\n",
    "#                 col_names=(\"output_size\", \"num_params\", \"kernel_size\"))\n",
    "# print(result)\n",
    "\n",
    "print(\"=== Estimated ===\")\n",
    "print_memory_estimate2(model_vgg16, [conf.batchsize] + conf.dim_input, \n",
    "                       conf.moment, conf.ddp, conf.mixed_pre)\n",
    "\n",
    "print(\"=== Real ===\")\n",
    "train(model_vgg16, [conf.datasize] + conf.dim_input, conf.batchsize, conf.num_epochs,\n",
    "      conf.optim, conf.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16では、理論値が15929MiB、実測値が17232MiB、誤差は7.6%であった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Estimated ===\n",
      "Data(MiB): 73.5\n",
      "Weight(MiB): 89.8\n",
      "Forward output(MiB): 5525.8\n",
      "Weight gradient(MiB): 89.8\n",
      "Output gradient(MiB): 5599.3\n",
      "Total for training(MiB): 11378.0\n",
      "Total for inference(MiB): 5689.0\n",
      "=== Real ===\n",
      "Initial: allocated = 1141.6 MiB, reserved = 7160.0MiB, max allocated = 1141.6 MiB, used = 11566.7 MiB\n",
      "Model: allocated = 1141.6 MiB, reserved = 7160.0MiB, max allocated = 1141.6 MiB, used = 11566.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|██████████| 10/10 [00:01<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 1307.0 MiB, reserved = 12982.0MiB, max allocated = 11738.2 MiB, used = 17392.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 10/10 [00:02<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 1307.0 MiB, reserved = 12982.0MiB, max allocated = 11738.2 MiB, used = 17392.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|██████████| 10/10 [00:02<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 1307.0 MiB, reserved = 12982.0MiB, max allocated = 11738.2 MiB, used = 17380.6 MiB\n",
      "Final: allocated = 1307.0 MiB, reserved = 12982.0MiB, max allocated = 11738.2 MiB, used = 17380.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_rn50 = models.resnet50(weights=None)\n",
    "model_rn50.fc = nn.Linear(model_rn50.fc.in_features, 10) # Change the num of final output features to 10\n",
    "# print(model_rn50)\n",
    "\n",
    "# result = summary(model_rn50, [conf.batchsize] + conf.dim_input,\n",
    "#                 col_names=(\"output_size\", \"num_params\", \"kernel_size\"))\n",
    "# print(result)\n",
    "\n",
    "print(\"=== Estimated ===\")\n",
    "print_memory_estimate2(model_rn50, [conf.batchsize] + conf.dim_input, \n",
    "                       conf.moment, conf.ddp, conf.mixed_pre)\n",
    "\n",
    "print(\"=== Real ===\")\n",
    "train(model_rn50, [conf.datasize] + conf.dim_input, conf.batchsize, conf.num_epochs,\n",
    "      conf.optim, conf.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50では、理論値が11378MiB、実測値が11738MiB、誤差は3.1%であった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22808851716326886"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(17217 - 13290) / 17217"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visiont Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=768, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "========================================================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #                   Kernel Shape\n",
      "========================================================================================================================\n",
      "VisionTransformer                             [128, 10]                 768                       --\n",
      "├─Conv2d: 1-1                                 [128, 768, 14, 14]        590,592                   [16, 16]\n",
      "├─Encoder: 1-2                                [128, 197, 768]           151,296                   --\n",
      "│    └─Dropout: 2-1                           [128, 197, 768]           --                        --\n",
      "│    └─Sequential: 2-2                        [128, 197, 768]           --                        --\n",
      "│    │    └─EncoderBlock: 3-1                 [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-2                 [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-3                 [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-4                 [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-5                 [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-6                 [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-7                 [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-8                 [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-9                 [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-10                [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-11                [128, 197, 768]           7,087,872                 --\n",
      "│    │    └─EncoderBlock: 3-12                [128, 197, 768]           7,087,872                 --\n",
      "│    └─LayerNorm: 2-3                         [128, 197, 768]           1,536                     --\n",
      "├─Sequential: 1-3                             [128, 10]                 --                        --\n",
      "│    └─Linear: 2-4                            [128, 10]                 7,690                     --\n",
      "========================================================================================================================\n",
      "Total params: 85,806,346\n",
      "Trainable params: 85,806,346\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 22.08\n",
      "========================================================================================================================\n",
      "Input size (MB): 77.07\n",
      "Forward/backward pass size (MB): 13322.95\n",
      "Params size (MB): 229.22\n",
      "Estimated Total Size (MB): 13629.25\n",
      "========================================================================================================================\n",
      "=== Estimated ===\n",
      "Data(MiB): 73.5\n",
      "Weight(MiB): 218.6\n",
      "Forward output(MiB): 6352.9\n",
      "Weight gradient(MiB): 218.6\n",
      "Output gradient(MiB): 6426.4\n",
      "Total for training(MiB): 13290.0\n",
      "Total for inference(MiB): 6645.0\n",
      "=== Real ===\n",
      "Initial: allocated = 1560.8 MiB, reserved = 8886.0MiB, max allocated = 1560.8 MiB, used = 13285.9 MiB\n",
      "Model: allocated = 1560.8 MiB, reserved = 8886.0MiB, max allocated = 1560.8 MiB, used = 13285.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|██████████| 10/10 [00:04<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 1964.8 MiB, reserved = 18238.0MiB, max allocated = 17217.2 MiB, used = 22615.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 10/10 [00:05<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 1964.8 MiB, reserved = 18238.0MiB, max allocated = 17217.2 MiB, used = 22608.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|██████████| 10/10 [00:05<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: allocated = 1964.8 MiB, reserved = 18238.0MiB, max allocated = 17217.2 MiB, used = 22619.7 MiB\n",
      "Final: allocated = 1964.8 MiB, reserved = 18238.0MiB, max allocated = 17217.2 MiB, used = 22619.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_vit = models.vit_b_16(weights=None)\n",
    "model_vit.heads[0] = nn.Linear(model_vit.heads[0].in_features, 10) # Change the num of final output features to 10\n",
    "print(model_vit)\n",
    "\n",
    "result = summary(model_vit, [conf.batchsize] + conf.dim_input,\n",
    "                col_names=(\"output_size\", \"num_params\", \"kernel_size\"))\n",
    "print(result)\n",
    "\n",
    "print(\"=== Estimated ===\")\n",
    "print_memory_estimate2(model_vit, [conf.batchsize] + conf.dim_input, \n",
    "                       conf.moment, conf.ddp, conf.mixed_pre)\n",
    "\n",
    "print(\"=== Real ===\")\n",
    "train(model_vit, [conf.datasize] + conf.dim_input, conf.batchsize, conf.num_epochs,\n",
    "      conf.optim, conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": allocated = 1891.3 MiB, reserved = 18238.0MiB, max allocated = 17217.2 MiB, used = 22622.5 MiB\n"
     ]
    }
   ],
   "source": [
    "print_memory_torch(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
